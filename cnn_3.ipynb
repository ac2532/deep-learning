{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "#imports for problem 2\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import json\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "#imports for problem 3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Transfer Learning with a Pre-Trained CNN\n",
    "Image classification using the Oxford Pet Dataset (37 categories with about 200 images in each of them).\n",
    "Rather than using the final ‘softmax’ layer of the CNN as output to make predictions as we did in problem 2, instead we will use the CNN as a feature extractor to classify the Pets dataset. For each image, grab features from the last hidden layer of the neural network, which will be the layer before the 1000-dimensional output layer (around 500– 6000 dimensions). You will need to resize the images to a size compatible with your network (usually 224 × 224 × 3, but look at the documentation for the pre-trained system you selected). You should grab the output just after the last hidden layer or after global pooling (if it is 1000-dimensional, you will know you did it wrong).\n",
    "After you extract these features for all of the images in the dataset, normalize them to unit length by dividing by the L2 norm. Train a linear classifier of your choice1 with the training CNN features, and then classify the test CNN features. Report mean-per-class accuracy and discuss the classifier you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Trainset size: 3680\n",
      "- Testset size: 3669\n",
      "- Number of classes: 37\n",
      "- Classes: ['Abyssinian', 'American Bulldog', 'American Pit Bull Terrier', 'Basset Hound', 'Beagle', 'Bengal', 'Birman', 'Bombay', 'Boxer', 'British Shorthair', 'Chihuahua', 'Egyptian Mau', 'English Cocker Spaniel', 'English Setter', 'German Shorthaired', 'Great Pyrenees', 'Havanese', 'Japanese Chin', 'Keeshond', 'Leonberger', 'Maine Coon', 'Miniature Pinscher', 'Newfoundland', 'Persian', 'Pomeranian', 'Pug', 'Ragdoll', 'Russian Blue', 'Saint Bernard', 'Samoyed', 'Scottish Terrier', 'Shiba Inu', 'Siamese', 'Sphynx', 'Staffordshire Bull Terrier', 'Wheaten Terrier', 'Yorkshire Terrier']\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Linear(in_features=512, out_features=1000, bias=True)\n",
      "Evaluation mode set\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "#dataset and data loaders\n",
    "train = torchvision.datasets.OxfordIIITPet(root='./data', split='trainval', transform=transform, download=True)\n",
    "test = torchvision.datasets.OxfordIIITPet(root='./data', split='test', transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f'- Trainset size: {len(train)}')\n",
    "print(f'- Testset size: {len(test)}')\n",
    "print(f'- Number of classes: {len(train.classes)}')\n",
    "print(f'- Classes: {train.classes}')\n",
    "\n",
    "#load pre-trained model, remove last fully connected layer and set to evaluation mode\n",
    "model = models.resnet18(weights= models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "print(list(model.children())[-3])\n",
    "print(list(model.children())[-2])\n",
    "print(list(model.children())[-1])\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "model.eval()\n",
    "print('Evaluation mode set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features for training \n",
    "train_features = []\n",
    "train_labels = []\n",
    "for images, labels in train_loader:\n",
    "    features = model(images)\n",
    "    features = features.view(features.size(0), -1)\n",
    "    train_features.append(features.detach().numpy())\n",
    "    train_labels.append(labels.detach().numpy())\n",
    "train_features = np.concatenate(train_features, axis=0)\n",
    "train_labels = np.concatenate(train_labels, axis=0)\n",
    "\n",
    "#extract features for test \n",
    "test_features = []\n",
    "test_labels = []\n",
    "for images, labels in test_loader:\n",
    "    features = model(images)\n",
    "    features = features.view(features.size(0), -1)\n",
    "    test_features.append(features.detach().numpy())\n",
    "    test_labels.append(labels.detach().numpy())\n",
    "test_features = np.concatenate(test_features, axis=0)\n",
    "test_labels = np.concatenate(test_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (3680, 512)\n",
      "Train labels shape: (3680,)\n",
      "Test features shape: (3669, 512)\n",
      "Test labels shape: (3669,)\n",
      "Predicted labels shape: (3669,)\n",
      "Mean per class accuracy: 0.894\n",
      "Mean-per-class accuracy using sklearn: 0.894\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")\n",
    "#normalize train and test features\n",
    "train_features_norm = np.linalg.norm(train_features, axis=1, keepdims=True)\n",
    "train_features = train_features / train_features_norm\n",
    "test_features_norm = np.linalg.norm(test_features, axis=1, keepdims=True)\n",
    "test_features = test_features / test_features_norm\n",
    "\n",
    "#train logistic regression classifier and predict classes for test data\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(train_features, train_labels)\n",
    "predicted_labels = classifier.predict(test_features)\n",
    "\n",
    "print(f\"Predicted labels shape: {predicted_labels.shape}\")\n",
    "\n",
    "#compute overall accuracy\n",
    "# accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "# print(f\"Overall accuracy: {accuracy:.3f}\")\n",
    "#compute mean per class accuracy\n",
    "class_accuracy = []\n",
    "for i in range(len(train.classes)):\n",
    "    class_accuracy.append(accuracy_score(test_labels[test_labels==i], predicted_labels[test_labels==i]))\n",
    "print(f\"Mean per class accuracy: {np.mean(class_accuracy):.3f}\")\n",
    "#computing mean-per-class accuracy using sklearn\n",
    "accuracy = balanced_accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"Mean-per-class accuracy using sklearn: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of each classes accuracies: \n",
      "[0.826530612244898, 0.91, 0.52, 0.9, 0.96, 0.88, 0.82, 0.9318181818181818, 0.9494949494949495, 0.77, 0.91, 0.8041237113402062, 0.92, 0.94, 0.98, 0.97, 0.98, 0.96, 1.0, 1.0, 0.82, 0.87, 0.98, 0.89, 0.93, 0.93, 0.74, 0.83, 0.99, 1.0, 0.98989898989899, 0.99, 0.89, 0.91, 0.5393258426966292, 0.91, 0.95]\n",
      "corresponding to: \n",
      "['Abyssinian', 'American Bulldog', 'American Pit Bull Terrier', 'Basset Hound', 'Beagle', 'Bengal', 'Birman', 'Bombay', 'Boxer', 'British Shorthair', 'Chihuahua', 'Egyptian Mau', 'English Cocker Spaniel', 'English Setter', 'German Shorthaired', 'Great Pyrenees', 'Havanese', 'Japanese Chin', 'Keeshond', 'Leonberger', 'Maine Coon', 'Miniature Pinscher', 'Newfoundland', 'Persian', 'Pomeranian', 'Pug', 'Ragdoll', 'Russian Blue', 'Saint Bernard', 'Samoyed', 'Scottish Terrier', 'Shiba Inu', 'Siamese', 'Sphynx', 'Staffordshire Bull Terrier', 'Wheaten Terrier', 'Yorkshire Terrier']\n"
     ]
    }
   ],
   "source": [
    "print(f'List of each classes accuracies: \\n{class_accuracy}')\n",
    "classes = train.classes\n",
    "print(f'corresponding to: \\n{classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discuss the classifier you used:\n",
    "\n",
    "I have used a logistic regression classifier for this image classification task (with sklearn). It is a linear classifier that is usually used for binary classification tasks but it has been interesting to see how it would perform for multi-class classification by training it on the features extracted from the last hidden layer of the pre-trained CNN (Resnet-18).\n",
    "The classifier uses the features extracted from ResNet-18 (output of the last hidden layer) as an input to predict the class labels of the images in the Oxford Pet Dataset. These features are first normalized to unit length by dividing by the L2 norm to scale the features and therefore improve the performance of the classifier.\n",
    "Logistic regression is a linear classifier and may not be the ideal choice for complex datasets with non-linear relationships such as pet images, however we can see that combining it to a CNN (ResNet-18) has given acceptable results in this case. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sources:\n",
    "- https://pytorch.org/vision/stable/models.html\n",
    "- ChatGPT, StackExchange, StackOverflow\n",
    "- https://learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ \n",
    "- https://www.kaggle.com/code/leifuer/intro-to-pytorch-loading-image-data\n",
    "- https://wandb.ai/shweta/Activation%20Functions/reports/Activation-Functions-Compared-With-Experiments--VmlldzoxMDQwOTQ#the-mish-activation-function\n",
    "- In-class MNIST Tutorial (google colab), CIFAR Tutorial\n",
    "- https://pytorch.org/docs/stable/generated/torch.linalg.norm.html#torch.linalg.norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
